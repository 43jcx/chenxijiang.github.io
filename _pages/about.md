---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I'm a third-year master's student, advised by [Prof. Zhenzhong Chen](http://iip.whu.edu.cn/~zzchen/index.html). I also work closely with [Prof. Jeremy M. Wolfe](https://eye.hms.harvard.edu/jeremywolfe) of Harvard Medical School. My research interest expands from machine vision to human vision. Now, I'm working on psychological experiments w.r.t. human cognitive behavior, including visual attention and visual working memory.

I enjoy reading, playing badminton, practicing yoga, especially watching movies. I view both movies and research as intricate arts. Great arts seem to be natural, with excellent thoughts and craftsmanship at closer observation. 

<!-- My research interest includes neural machine translation and computer vision. I have published more than 100 papers at the top international AI conferences with total <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'>google scholar citations <strong><span id='total_cit'>260000+</span></strong></a> (You can also use google scholar badge <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'><img src="https://img.shields.io/endpoint?url={{ url | url_encode }}&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations"></a>). -->

# üìñ Educations
- *2021.09 - now*,     graduate student in [School of Remote Sensing and Information Engineering](https://rsgis.whu.edu.cn/English/Home.htm), [Wuhan University](https://en.whu.edu.cn/). 
- *2017.09 - 2021.06*, B.Eng. in [School of Remote Sensing and Information Engineering](https://rsgis.whu.edu.cn/English/Home.htm), [Wuhan University](https://en.whu.edu.cn/). 

# üî• News
- *2023.01*: &nbsp;üéâüéâ 2nd Price, "Optics Valley Of China¬∑Huawei Cup‚Äù The 19th China Post-Graduate Mathematical Contest in Modeling. 
<!-- - *2022.02*: &nbsp;üéâüéâ .  -->

# üìù Publications 
- Now, I'm working on exploring the influence of semantics on the encoding and retrieval of visual working memory.

<div class='paper-box-text' markdown="1">
[1]	**Jiang, C.**, Chen Z. and Wolfe, J. M., Towards viewing behavior for aerial scene categorization, Cognitive Research: Principles and Implications. (Under review) [_Data & Codes_](https://osf.io/4n3rc/).
</div>
<div class='paper-box-text' markdown="1">  
[2]	Chen, Z., Zhang, K., Cai, H., Ding, X., **Jiang, C.**, Chen, Z., Audio-visual saliency prediction for movie viewing in immersive environment: Dataset and benchmarks, J. Vis. Commun. Image Represent. (Under revision)
</div>
<div class='paper-box-text' markdown="1">
[3]	Cai, H., Zhang, K., Chen, Z., **Jiang, C.**, Chen, Z., Title omitted, VCIP 2023. (Under double blind review)
</div>
<div class='paper-box-text' markdown="1">
[4]	Li, Y., Zhang, K., Chen, Z., Ouyang, W., Cui, M., **Jiang, C.**, Yang, D., Chen, Z., Towards object tracking for quadruped robots, J. Vis. Commun. Image Represent. (Under revision)
</div>


<!-- <div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2016</div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Deep Residual Learning for Image Recognition](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)

**Kaiming He**, Xiangyu Zhang, Shaoqing Ren, Jian Sun

[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
</div>
</div> -->

<!-- - [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020** -->

# üíª Standard Proposals
- Zhu, H., **Jiang, C.**, Zhang, Z., Zhang, Y., Chen, C., VC-37-M321, ‚ÄúDraft of the subjective quality assessment test‚Äù, Online, Mar. 2022. (IEEE 1857 Standard proposal)
- Zhu, H., **Jiang, C.**, Zhang, J., Chen, Z., VC-38-M344, ‚ÄúSubjective quality assessment results of CfP‚Äù, Online, Jun. 2022. (IEEE 1857 Standard proposal)

# üéñ Honors and Awards
- *2023.01* 2nd Price, "Optics Valley Of China¬∑Huawei Cup‚Äù The 19th China Post-Graduate Mathematical Contest in Modeling
- *2021.09* 1st Prize, Freshman Scholarship
- *2021.06* Outstanding Graduate, Wuhan University
- *2020.05* 1st Prize, "Hongtuchuangzhan (Macro-vision Innovation)" Special Scholarship
- *2019.05* **National Scholarship**

# üí¨ Beyond research
- I've always dreamt of directing a movie.
- Animals are our beloved friends. PS: I have two cute cats. See the page icon!

<!-- # üí¨ Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/) -->

<!-- # üíª Internships
- *2019.05 - 2020.02*, [Lorem](https://github.com/), China.
 -->
